#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆ Gradio å›¾åƒç”Ÿæˆåº”ç”¨
ç¦ç”¨ SvelteKit SSRï¼Œæ¢å¤æ ‡å‡† /run/predict POST æ¥å£
"""

import gradio as gr
from diffusers import StableDiffusionXLPipeline
import torch
import os
from typing import List, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
pipe = None

def load_model():
    """åŠ è½½ Stable Diffusion XL æ¨¡å‹"""
    global pipe
    try:
        logger.info("æ­£åœ¨åŠ è½½ Stable Diffusion XL æ¨¡å‹...")
        
        # ä½¿ç”¨ SDXL åŸºç¡€æ¨¡å‹
        model_id = "stabilityai/stable-diffusion-xl-base-1.0"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ GPU
        device = "cuda" if torch.cuda.is_available() else "cpu"
        torch_dtype = torch.float16 if device == "cuda" else torch.float32
        
        # pipe = StableDiffusionXLPipeline.from_pretrained(
        #     model_id,
        #     torch_dtype=torch_dtype,
        #     use_safetensors=True,
        #     variant="fp16" if device == "cuda" else None
        # )

        pipe = StableDiffusionXLPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0"
        ).to("cpu")

        pipe = pipe.to(device)
        
        # å¯ç”¨å†…å­˜ä¼˜åŒ–
        if device == "cuda":
            pipe.enable_model_cpu_offload()
            pipe.enable_vae_slicing()
            pipe.enable_attention_slicing()
        
        logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {device}")
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def generate_images(
    prompt: str,
    negative_prompt: str = "low quality, blurry, distorted, bad anatomy, worst quality",
    guidance_scale: float = 7.5,
    num_inference_steps: int = 28,
    width: int = 1024,
    height: int = 1024,
    seed: int = -1,
    num_outputs: int = 4
) -> List[str]:
    """
    ç”Ÿæˆå›¾åƒ
    
    Args:
        prompt: æ­£é¢æç¤ºè¯
        negative_prompt: è´Ÿé¢æç¤ºè¯
        guidance_scale: CFG å¼•å¯¼å¼ºåº¦
        num_inference_steps: æ¨ç†æ­¥æ•°
        width: å›¾åƒå®½åº¦
        height: å›¾åƒé«˜åº¦
        seed: éšæœºç§å­ (-1 è¡¨ç¤ºéšæœº)
        num_outputs: ç”Ÿæˆæ•°é‡
    
    Returns:
        ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨
    """
    global pipe
    
    if pipe is None:
        if not load_model():
            raise gr.Error("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
    
    try:
        # è®¾ç½®éšæœºç§å­
        if seed == -1:
            seed = torch.randint(0, 2**32 - 1, (1,)).item()
        
        generator = torch.Generator(device=pipe.device).manual_seed(seed)
        
        logger.info(f"å¼€å§‹ç”Ÿæˆå›¾åƒ: prompt='{prompt[:50]}...', seed={seed}")
        
        # ç”Ÿæˆå›¾åƒ
        with torch.autocast(pipe.device.type):
            result = pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps,
                width=width,
                height=height,
                num_images_per_prompt=num_outputs,
                generator=generator
            )
        
        images = result.images
        logger.info(f"æˆåŠŸç”Ÿæˆ {len(images)} å¼ å›¾åƒ")
        
        return images
        
    except Exception as e:
        logger.error(f"å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
        raise gr.Error(f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")

def create_interface():
    """åˆ›å»º Gradio ç•Œé¢ - å¼ºåˆ¶ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼"""
    
    # ğŸ”¥ å…³é”®ï¼šä½¿ç”¨ gr.Interface è€Œä¸æ˜¯ gr.Blocks æ¥ç¡®ä¿ä¼ ç»Ÿ API
    interface = gr.Interface(
        fn=generate_images,
        inputs=[
            gr.Textbox(
                label="æç¤ºè¯ (Prompt)",
                placeholder="æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„å›¾åƒ...",
                lines=3,
                value="a beautiful landscape with mountains and sunset, highly detailed, photorealistic"
            ),
            gr.Textbox(
                label="è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                placeholder="æè¿°æ‚¨ä¸æƒ³è¦çš„å…ƒç´ ...",
                lines=2,
                value="low quality, blurry, distorted, bad anatomy, worst quality"
            ),
            gr.Slider(
                label="CFG å¼•å¯¼å¼ºåº¦",
                minimum=1.0,
                maximum=20.0,
                value=7.5,
                step=0.5
            ),
            gr.Slider(
                label="æ¨ç†æ­¥æ•°",
                minimum=10,
                maximum=50,
                value=28,
                step=1
            ),
            gr.Slider(
                label="å®½åº¦",
                minimum=512,
                maximum=1536,
                value=1024,
                step=64
            ),
            gr.Slider(
                label="é«˜åº¦",
                minimum=512,
                maximum=1536,
                value=1024,
                step=64
            ),
            gr.Number(
                label="éšæœºç§å­ (-1 è¡¨ç¤ºéšæœº)",
                value=-1,
                precision=0
            ),
            gr.Slider(
                label="ç”Ÿæˆæ•°é‡",
                minimum=1,
                maximum=4,
                value=4,
                step=1
            )
        ],
        outputs=gr.Gallery(
            label="ç”Ÿæˆçš„å›¾åƒ",
            columns=2,
            rows=2,
            height="auto"
        ),
        title="ğŸ¨ AI å›¾åƒç”Ÿæˆå™¨",
        description="""
        åŸºäº Stable Diffusion XL çš„é«˜è´¨é‡å›¾åƒç”ŸæˆæœåŠ¡
        
        **ç‰¹æ€§**ï¼š
        - âœ… æ”¯æŒæ ‡å‡† `/run/predict` POST æ¥å£
        - âœ… é«˜è´¨é‡ SDXL æ¨¡å‹
        - âœ… å¯è‡ªå®šä¹‰å‚æ•°
        - âœ… æ‰¹é‡ç”Ÿæˆ
        """,
        examples=[
            [
                "a majestic dragon flying over a medieval castle, fantasy art, highly detailed",
                "low quality, blurry",
                7.5, 28, 1024, 1024, -1, 4
            ],
            [
                "a futuristic city with flying cars, cyberpunk style, neon lights",
                "low quality, blurry, distorted",
                8.0, 30, 1024, 1024, -1, 4
            ],
            [
                "a serene forest with sunlight filtering through trees, photorealistic",
                "low quality, cartoon, anime",
                7.0, 25, 1024, 1024, -1, 4
            ]
        ],
        # ğŸ”¥ å…³é”®é…ç½®ï¼šç¡®ä¿ä¼ ç»Ÿ API å¯ç”¨
        api_name="predict",  # æ˜ç¡®æŒ‡å®š API åç§°
        allow_flagging="never",
        cache_examples=False
    )
    
    return interface

if __name__ == "__main__":
    # é¢„åŠ è½½æ¨¡å‹
    logger.info("å¯åŠ¨åº”ç”¨...")
    load_model()
    
    # åˆ›å»ºç•Œé¢
    demo = create_interface()
    
    # ğŸ”¥ å…³é”®å¯åŠ¨é…ç½®ï¼šç¦ç”¨ SvelteKitï¼Œå¼ºåˆ¶ä¼ ç»Ÿæ¨¡å¼
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_api=True,          # æ˜¾ç¤º API æ–‡æ¡£
        show_error=True,
        enable_queue=True,      # å¯ç”¨é˜Ÿåˆ—ç³»ç»Ÿ
        max_threads=10,         # æœ€å¤§çº¿ç¨‹æ•°
        # ğŸ”¥ å…³é”®ï¼šç¦ç”¨ç°ä»£ UI ç‰¹æ€§ï¼Œå¼ºåˆ¶ä¼ ç»Ÿæ¨¡å¼
        favicon_path=None,
        ssl_keyfile=None,
        ssl_certfile=None,
        ssl_keyfile_password=None,
        quiet=False,
        show_tips=False,
        height=600,
        width="100%",
        prevent_thread_lock=False,
        auth=None,
        auth_message=None,
        blocked_paths=None,
        allowed_paths=None,
        root_path=None,
        app_kwargs={}
    ) 